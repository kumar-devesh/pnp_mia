---
seed: 42

model:
  architecture: ViT  # Model architecture, e.g., resnet50, densenet169, inceptionv3.
  num_classes: 1000 # Number of classes in the training set. [facescrub:530, celebA:1000]
  pretrained: false # Using the ImageNet weights for initialization. [true , false , yes , no , on , and off ]

dataset:
  type: celeba_identities # Select on of [facescrub, celeba_identities, stanford_dogs_cropped, stanford_dogs_uncropped].
  # training_set_size: 2500 # Number of training samples. Delete to use all samples in the dataset.
  # validation_set_size: 0 # Absolute number validation samples taken from the training set.
  validation_split_ratio: 0.1 # Alternative to validation_set_size, split is taken from the training set.
  image_size: 224 # Image size of training samples before application of transformations.

transformations: # Transformations applied during training. 
                 # All transformations and parameters provided in torchvision.transforms could be specified.
  RandomResizedCrop:
    size: [224, 224]
    scale: [0.75, 1]
    ratio: [1, 1]
  ColorJitter:
    brightness: 0.2
    contrast: 0.2
    saturation: 0.0
    hue: 0.0
  RandomHorizontalFlip:
    p: 0.5

optimizer:  # Specify the optimizer and its parameters from torch.optim for training.
  Adam:
    lr: 0.0001 # resnets.. 1e-3, Vit..1e-4
    betas: [0.9, 0.999]
    weight_decay: 0

lr_scheduler: # Option to provide a learning rate scheduler from torch.optim.
  # MultiStepLR:
  #   milestones: [30, 50]
  #   gamma: 0.1
  CosineAnnealingLR:
    T_max: 100

training: # Select the training parameters.
  num_epochs: 100
  batch_size: 64
  dataloader_num_workers: 8
  save_path: target_models/

rtpt: # State RTPT details. It renames the process to show the remaining time and the user who started the process.
  experiment_name: Training target classifier
  name_initials: XX

wandb: # Options for WandB logging.
  enable_logging: true # Set to true to activate the logging.
  args: # Arguments for wandb.init call. See https://docs.wandb.ai/ref/python/init for a complete overview.
    project: model_inversion_targets
    name: ViT_CelebA
    save_code: true
    notes: Training a target model
    tags:
      - Some
      - Tags
